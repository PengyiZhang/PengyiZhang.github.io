# 【计算机视觉】关于`partial cross entropy loss`用于弱监督语义分割中的说明

## 弱监督标签

以两语义分割为例，背景和前景，给定的弱监督标签是只对前景个一小部分进行了标注。这个只是直接拿这个弱监督标签进行训练，会有一定的问题，因为大部分的前景标签都没有标注出来，所以前景类别会受到较大的抑制。


GT标签：![](/img/20200412/Figure2.png)

Weak标签：![](/img/20200412/Figure0.png)

## 采用 `partial cross entropy loss`

意思是只在有标注的像素上计算`cross entropy loss`。前景目标为1，那么对应的 `loss=-∑t_i*log(p_i)`, `i` 为像素索引, `t_i` 为对应的真实标签，`p_i` 为对应的分割输出是前景的概率。对比正常的`cross entropy loss`，少了对于真实标签为`0`的部分的loss计算：`loss=-∑t_i*log(p_i)-∑(1-t_i)*log(1-p_i)`，也就是说认为弱标签只是提供了对前景的标注。因此，计算时只对有标注的像素计算损失。

## 问题及改进

很明显，这样的训练方式会导致模型尽可能的输出前景标签，因为将是前景的像素分类为背景会受到惩罚，而将是背景的像素分类为前景则不会受到惩罚。其训练的效果如下图所示：

![](/img/20200412/Figure1.png)

而真实的GT标签为：

![](/img/20200412/Figure2.png)

所以，很显然这样的效果不令人满意。

那么有什么办法能够改进呢？

回到这个弱标签本身，提供的训练图像数据集是这样的约定：弱标签虽然很弱，但是却是很讲究的，因为但凡有前景存在的图像它都会至少标注一个像素，而没有前景存在的图像它是不需要标注的。这样就给了一个可以用于抑制背景的惩罚项。那就是对于训练时，判断图像中有没有前景目标，有的话计算partial cross entropy loss，而没有的话则计算对背景的约束项，也就是这半边的损失`loss=-∑(1-t_i)*log(1-p_i)`。从而能够在一定程度上提供对背景的监督，防止前景过于弥散。

对应的训练结果为：

![](/img/20200412/Figure3.png)


这里训练效果还是很好地。因为在训练数据集中大约有 `83/1674=0.04958183990442055` 属于全`Negative`的训练样本。`83`张足够提供给样本良好的背景监督，抑制由于`partial label`导致的前景扩张。

## 其它弱监督语义分割技术

上面提出的改进方法比较简单，适用性必须有两个前提：1. 默认含有前景的图像都至少有一个像素的标注，即没有标注的图像全是背景类；2. 数据集中存在一定量的全是背景类的样本，能够用于约束前景的扩张。

若不满足该条件，可能需要尝试其它弱监督语义分割技术。

其余方法可以尝试 弱监督语义分割的相关技术，可以参考：[https://github.com/PengyiZhang/MIADeepSSL/tree/master/01_WeaklySupervised](https://github.com/PengyiZhang/MIADeepSSL/tree/master/01_WeaklySupervised)



-----
20200412