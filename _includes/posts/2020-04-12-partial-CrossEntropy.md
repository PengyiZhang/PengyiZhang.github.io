# 【计算机视觉】关于`partial cross entropy loss`用于弱监督语义分割中的说明

## 弱监督标签

以两语义分割为例，背景和前景，给定的弱监督标签是只对前景个一小部分进行了标注。这个只是直接拿这个弱监督标签进行训练，会有一定的问题，因为大部分的前景标签都没有标注出来，所以前景类别会受到较大的抑制。

## 采用 `partial cross entropy loss`

意思是只在有标注的像素上计算`cross entropy loss`。前景目标为1，那么对应的 `loss=-∑t_i*log(p_i)`, `i` 为像素索引, `t_i` 为对应的真实标签，`p_i` 为对应的分割输出是前景的概率。对比正常的`cross entropy loss`，少了对于真实标签为`0`的部分的loss计算：`loss=-∑t_i*log(p_i)-∑(1-t_i)*log(1-p_i)`，也就是说认为弱标签只是提供了对前景的标注。因此，计算时只对有标注的像素计算损失。

## 问题及改进

很明显，这样的训练方式会导致模型尽可能的输出前景标签，因为将是前景的像素分类为背景会受到惩罚，而将是背景的像素分类为前景则不会受到惩罚。其训练的效果如下图所示：

![](/img/20200411/Figure1.png)

而真实的GT标签为：

![](/img/20200411/Figure2.png)

所以，很显然这样的效果不令人满意。

那么有什么办法能够改进呢？

回到这个弱标签本身，提供的训练图像数据集是这样的约定：弱标签虽然很弱，但是却是很讲究的，因为但凡有前景存在的图像它都会至少标注一个像素，而没有前景存在的图像它是不需要标注的。这样就给了一个可以用于抑制背景的惩罚项。那就是对于训练时，判断图像中有没有前景目标，有的话计算partial cross entropy loss，而没有的话则计算对背景的约束项，也就是这半边的损失`loss=-∑(1-t_i)*log(1-p_i)`。从而能够在一定程度上提供对背景的监督，防止前景过于弥散。




其余方法可以尝试 弱监督语义分割的相关技术，比如：[https://github.com/PengyiZhang/MIADeepSSL/tree/master/01_WeaklySupervised](https://github.com/PengyiZhang/MIADeepSSL/tree/master/01_WeaklySupervised)



-----
20200412